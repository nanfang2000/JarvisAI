import React, { useState, useEffect, useRef } from 'react';
import {
  Box,
  Typography,
  Paper,
  Button,
  LinearProgress,
  IconButton,
  Tooltip,
  Switch,
  FormControlLabel,
} from '@mui/material';
import {
  Videocam,
  VideocamOff,
  Mic,
  MicOff,
  Settings,
  Psychology,
  Visibility,
  VisibilityOff,
  ThreeDRotation,
  Face,
} from '@mui/icons-material';
import { VoiceAvatarIntegration } from '../voice';
import { EmotionType } from '../../types/avatar';

interface AvatarPanelProps {
  isConnected: boolean;
  jarvisStatus: any;
  onShowNotification: (message: string, severity?: 'info' | 'success' | 'warning' | 'error') => void;
}

interface AvatarState {
  cameraEnabled: boolean;
  micEnabled: boolean;
  isThinking: boolean;
  thinkingProgress: number;
  emotionalState: 'neutral' | 'happy' | 'thinking' | 'listening' | 'speaking';
  lipSyncActive: boolean;
  faceDetected: boolean;
  currentExpression: string;
  show3DAvatar: boolean;
  currentEmotion: EmotionType;
  isListening: boolean;
  isSpeaking: boolean;
  recognizedText: string;
}

const AvatarPanel: React.FC<AvatarPanelProps> = ({
  isConnected,
  jarvisStatus,
  onShowNotification,
}) => {
  const [state, setState] = useState<AvatarState>({
    cameraEnabled: false,
    micEnabled: false,
    isThinking: false,
    thinkingProgress: 0,
    emotionalState: 'neutral',
    lipSyncActive: false,
    faceDetected: false,
    currentExpression: 'ğŸ˜Š',
    show3DAvatar: true,
    currentEmotion: EmotionType.NEUTRAL,
    isListening: false,
    isSpeaking: false,
    recognizedText: '',
  });

  const videoRef = useRef<HTMLVideoElement>(null);
  const canvasRef = useRef<HTMLCanvasElement>(null);

  // å¤„ç†è¯­éŸ³è¾“å…¥
  const handleVoiceInput = (text: string) => {
    setState(prev => ({ 
      ...prev, 
      recognizedText: text,
      emotionalState: 'listening',
      currentEmotion: EmotionType.THINKING
    }));
    console.log('Voice input:', text);
  };

  // å¤„ç†è¯­éŸ³è¾“å‡º
  const handleVoiceOutput = (text: string) => {
    setState(prev => ({ 
      ...prev, 
      emotionalState: 'speaking',
      currentEmotion: EmotionType.SPEAKING
    }));
    console.log('Voice output:', text);
  };

  // å¤„ç†æƒ…æ„Ÿå˜åŒ–
  const handleEmotionChange = (emotion: EmotionType) => {
    setState(prev => ({ ...prev, currentEmotion: emotion }));
    
    // åŒæ­¥åˆ°è¡¨æƒ…çŠ¶æ€
    switch (emotion) {
      case EmotionType.HAPPY:
        setState(prev => ({ ...prev, emotionalState: 'happy', currentExpression: 'ğŸ˜Š' }));
        break;
      case EmotionType.THINKING:
        setState(prev => ({ ...prev, emotionalState: 'thinking', currentExpression: 'ğŸ¤”' }));
        break;
      case EmotionType.SPEAKING:
        setState(prev => ({ ...prev, emotionalState: 'speaking', currentExpression: 'ğŸ’¬' }));
        break;
      default:
        setState(prev => ({ ...prev, emotionalState: 'neutral', currentExpression: 'ğŸ˜Š' }));
    }
  };

  // å¤„ç†ç›‘å¬çŠ¶æ€å˜åŒ–
  const handleListeningChange = (listening: boolean) => {
    setState(prev => ({ 
      ...prev, 
      isListening: listening,
      emotionalState: listening ? 'listening' : 'neutral',
      currentEmotion: listening ? EmotionType.NEUTRAL : EmotionType.NEUTRAL
    }));
  };

  // å¤„ç†è¯´è¯çŠ¶æ€å˜åŒ–
  const handleSpeakingChange = (speaking: boolean) => {
    setState(prev => ({ 
      ...prev, 
      isSpeaking: speaking,
      emotionalState: speaking ? 'speaking' : 'neutral',
      currentEmotion: speaking ? EmotionType.SPEAKING : EmotionType.NEUTRAL,
      lipSyncActive: speaking
    }));
  };

  // åˆ‡æ¢3Då¤´åƒæ˜¾ç¤º
  const toggle3DAvatar = () => {
    setState(prev => ({ ...prev, show3DAvatar: !prev.show3DAvatar }));
    onShowNotification(
      state.show3DAvatar ? 'å·²åˆ‡æ¢åˆ°2Dæ¨¡å¼' : 'å·²åˆ‡æ¢åˆ°3Då¤´åƒæ¨¡å¼', 
      'info'
    );
  };

  // æ‘„åƒå¤´æ§åˆ¶
  const toggleCamera = async () => {
    try {
      if (!state.cameraEnabled) {
        const stream = await navigator.mediaDevices.getUserMedia({ video: true });
        if (videoRef.current) {
          videoRef.current.srcObject = stream;
          videoRef.current.play();
        }
        setState(prev => ({ ...prev, cameraEnabled: true }));
        onShowNotification('æ‘„åƒå¤´å·²å¯ç”¨', 'success');
      } else {
        if (videoRef.current && videoRef.current.srcObject) {
          const tracks = (videoRef.current.srcObject as MediaStream).getTracks();
          tracks.forEach(track => track.stop());
          videoRef.current.srcObject = null;
        }
        setState(prev => ({ ...prev, cameraEnabled: false, faceDetected: false }));
        onShowNotification('æ‘„åƒå¤´å·²å…³é—­', 'info');
      }
    } catch (error) {
      console.error('æ‘„åƒå¤´æ“ä½œå¤±è´¥:', error);
      onShowNotification('æ‘„åƒå¤´æ“ä½œå¤±è´¥ï¼Œè¯·æ£€æŸ¥æƒé™', 'error');
    }
  };

  // éº¦å…‹é£æ§åˆ¶
  const toggleMic = async () => {
    try {
      if (!state.micEnabled) {
        await navigator.mediaDevices.getUserMedia({ audio: true });
        setState(prev => ({ ...prev, micEnabled: true }));
        onShowNotification('éº¦å…‹é£å·²å¯ç”¨', 'success');
      } else {
        setState(prev => ({ ...prev, micEnabled: false }));
        onShowNotification('éº¦å…‹é£å·²å…³é—­', 'info');
      }
    } catch (error) {
      console.error('éº¦å…‹é£æ“ä½œå¤±è´¥:', error);
      onShowNotification('éº¦å…‹é£æ“ä½œå¤±è´¥ï¼Œè¯·æ£€æŸ¥æƒé™', 'error');
    }
  };

  // æ¨¡æ‹Ÿæ€è€ƒçŠ¶æ€
  const simulateThinking = () => {
    setState(prev => ({ ...prev, isThinking: true, emotionalState: 'thinking' }));
    
    const interval = setInterval(() => {
      setState(prev => {
        const newProgress = prev.thinkingProgress + 10;
        if (newProgress >= 100) {
          clearInterval(interval);
          setTimeout(() => {
            setState(current => ({
              ...current,
              isThinking: false,
              thinkingProgress: 0,
              emotionalState: 'neutral',
            }));
          }, 500);
          return { ...prev, thinkingProgress: 100 };
        }
        return { ...prev, thinkingProgress: newProgress };
      });
    }, 200);
  };

  // ç®€å•çš„äººè„¸æ£€æµ‹æ¨¡æ‹Ÿ
  useEffect(() => {
    if (state.cameraEnabled && videoRef.current) {
      const detectFace = () => {
        // è¿™é‡Œåº”è¯¥é›†æˆå®é™…çš„äººè„¸æ£€æµ‹é€»è¾‘
        // ç›®å‰ä½¿ç”¨æ¨¡æ‹Ÿ
        const detected = Math.random() > 0.3; // 70%æ¦‚ç‡æ£€æµ‹åˆ°äººè„¸
        setState(prev => ({ ...prev, faceDetected: detected }));
      };

      const interval = setInterval(detectFace, 2000);
      return () => clearInterval(interval);
    }
  }, [state.cameraEnabled]);

  // è¡¨æƒ…å˜åŒ–åŠ¨ç”»
  useEffect(() => {
    const expressions = ['ğŸ˜Š', 'ğŸ¤”', 'ğŸ‘€', 'ğŸ˜„', 'ğŸ™‚'];
    let currentIndex = 0;

    const interval = setInterval(() => {
      if (state.emotionalState === 'thinking') {
        setState(prev => ({ ...prev, currentExpression: 'ğŸ¤”' }));
      } else if (state.emotionalState === 'listening') {
        setState(prev => ({ ...prev, currentExpression: 'ğŸ‘‚' }));
      } else if (state.emotionalState === 'speaking') {
        setState(prev => ({ ...prev, currentExpression: 'ğŸ’¬' }));
      } else {
        currentIndex = (currentIndex + 1) % expressions.length;
        setState(prev => ({ ...prev, currentExpression: expressions[currentIndex] }));
      }
    }, 3000);

    return () => clearInterval(interval);
  }, [state.emotionalState]);

  return (
    <Box
      sx={{
        height: '100%',
        display: 'flex',
        flexDirection: 'column',
        p: 2,
        gap: 2,
      }}
    >
      {/* æ ‡é¢˜åŒºåŸŸ */}
      <Paper
        elevation={2}
        sx={{
          p: 2,
          textAlign: 'center',
          bgcolor: 'rgba(100, 181, 246, 0.1)',
          border: '1px solid rgba(100, 181, 246, 0.3)',
        }}
      >
        <Typography variant="h6" color="primary" gutterBottom>
          JARVIS AI
        </Typography>
        <Typography variant="caption" color="text.secondary">
          æ‚¨çš„æ™ºèƒ½ç®¡å®¶å°çˆ±
        </Typography>
      </Paper>

      {/* 3D AvataråŒºåŸŸ */}
      <Paper
        elevation={3}
        sx={{
          flex: 1,
          display: 'flex',
          flexDirection: 'column',
          position: 'relative',
          overflow: 'hidden',
          bgcolor: state.show3DAvatar ? 'black' : 'background.paper',
        }}
      >
        {state.show3DAvatar ? (
          /* 3Då¤´åƒé›†æˆç»„ä»¶ */
          <VoiceAvatarIntegration
            onVoiceInput={handleVoiceInput}
            onVoiceOutput={handleVoiceOutput}
            currentText={state.recognizedText}
            isListening={state.isListening}
            isSpeaking={state.isSpeaking}
            onListeningChange={handleListeningChange}
            onSpeakingChange={handleSpeakingChange}
          />
        ) : (
          /* ä¼ ç»Ÿ2Dæ˜¾ç¤º */
          <Box
            sx={{
              display: 'flex',
              flexDirection: 'column',
              alignItems: 'center',
              justifyContent: 'center',
              p: 2,
              height: '100%',
            }}
          >
            <Box
              sx={{
                width: 200,
                height: 200,
                borderRadius: '50%',
                background: 'linear-gradient(135deg, #64B5F6, #81C784)',
                display: 'flex',
                alignItems: 'center',
                justifyContent: 'center',
                fontSize: 80,
                mb: 2,
                animation: state.isThinking ? 'pulse 1.5s infinite' : 'none',
                '@keyframes pulse': {
                  '0%': {
                    transform: 'scale(1)',
                    opacity: 1,
                  },
                  '50%': {
                    transform: 'scale(1.05)',
                    opacity: 0.8,
                  },
                  '100%': {
                    transform: 'scale(1)',
                    opacity: 1,
                  },
                },
              }}
            >
              {state.currentExpression}
            </Box>
          </Box>
        )}

        {/* çŠ¶æ€æŒ‡ç¤ºå™¨ */}
        <Box sx={{ width: '100%', textAlign: 'center' }}>
          <Typography variant="body2" color="text.secondary" gutterBottom>
            {state.isThinking
              ? 'æ·±åº¦æ€è€ƒä¸­...'
              : state.emotionalState === 'listening'
              ? 'æ­£åœ¨è†å¬...'
              : state.emotionalState === 'speaking'
              ? 'æ­£åœ¨å›å¤...'
              : 'ç­‰å¾…æŒ‡ä»¤'}
          </Typography>

          {/* æ€è€ƒè¿›åº¦æ¡ */}
          {state.isThinking && (
            <LinearProgress
              variant="determinate"
              value={state.thinkingProgress}
              sx={{ mt: 1, borderRadius: 1 }}
            />
          )}

          {/* å˜´å‹åŒæ­¥æŒ‡ç¤ºå™¨ */}
          {state.lipSyncActive && (
            <Box
              sx={{
                mt: 1,
                display: 'flex',
                justifyContent: 'center',
                gap: 0.5,
              }}
            >
              {[1, 2, 3, 4, 5].map((bar) => (
                <Box
                  key={bar}
                  sx={{
                    width: 4,
                    height: Math.random() * 20 + 10,
                    bgcolor: 'primary.main',
                    borderRadius: 1,
                    animation: 'lipSync 0.5s infinite alternate',
                    animationDelay: `${bar * 0.1}s`,
                    '@keyframes lipSync': {
                      '0%': {
                        transform: 'scaleY(0.3)',
                      },
                      '100%': {
                        transform: 'scaleY(1)',
                      },
                    },
                  }}
                />
              ))}
            </Box>
          )}
        </Box>

        {/* è¿æ¥çŠ¶æ€è¦†ç›–å±‚ */}
        {!isConnected && (
          <Box
            sx={{
              position: 'absolute',
              top: 0,
              left: 0,
              right: 0,
              bottom: 0,
              bgcolor: 'rgba(0, 0, 0, 0.7)',
              display: 'flex',
              alignItems: 'center',
              justifyContent: 'center',
              flexDirection: 'column',
            }}
          >
            <Typography variant="h6" color="error" gutterBottom>
              è¿æ¥ä¸­æ–­
            </Typography>
            <Typography variant="body2" color="text.secondary">
              æ­£åœ¨å°è¯•é‡æ–°è¿æ¥...
            </Typography>
          </Box>
        )}
      </Paper>

      {/* æ‘„åƒå¤´é¢„è§ˆåŒºåŸŸ */}
      {state.cameraEnabled && (
        <Paper
          elevation={2}
          sx={{
            height: 120,
            overflow: 'hidden',
            position: 'relative',
            bgcolor: 'black',
          }}
        >
          <video
            ref={videoRef}
            style={{
              width: '100%',
              height: '100%',
              objectFit: 'cover',
            }}
            muted
          />
          <canvas
            ref={canvasRef}
            style={{
              position: 'absolute',
              top: 0,
              left: 0,
              width: '100%',
              height: '100%',
              pointerEvents: 'none',
            }}
          />
          
          {/* äººè„¸æ£€æµ‹æŒ‡ç¤ºå™¨ */}
          {state.faceDetected && (
            <Box
              sx={{
                position: 'absolute',
                top: 8,
                right: 8,
                bgcolor: 'success.main',
                color: 'white',
                px: 1,
                py: 0.5,
                borderRadius: 1,
                fontSize: 12,
              }}
            >
              äººè„¸å·²è¯†åˆ«
            </Box>
          )}
        </Paper>
      )}

      {/* æ§åˆ¶æŒ‰é’®åŒºåŸŸ */}
      <Paper elevation={1} sx={{ p: 1 }}>
        <Box
          sx={{
            display: 'grid',
            gridTemplateColumns: '1fr 1fr 1fr',
            gap: 1,
          }}
        >
          {/* æ‘„åƒå¤´æ§åˆ¶ */}
          <Tooltip title={state.cameraEnabled ? 'å…³é—­æ‘„åƒå¤´' : 'å¼€å¯æ‘„åƒå¤´'}>
            <IconButton
              onClick={toggleCamera}
              color={state.cameraEnabled ? 'primary' : 'default'}
              sx={{
                bgcolor: state.cameraEnabled ? 'primary.dark' : 'action.hover',
              }}
            >
              {state.cameraEnabled ? <Videocam /> : <VideocamOff />}
            </IconButton>
          </Tooltip>

          {/* éº¦å…‹é£æ§åˆ¶ */}
          <Tooltip title={state.micEnabled ? 'å…³é—­éº¦å…‹é£' : 'å¼€å¯éº¦å…‹é£'}>
            <IconButton
              onClick={toggleMic}
              color={state.micEnabled ? 'primary' : 'default'}
              sx={{
                bgcolor: state.micEnabled ? 'primary.dark' : 'action.hover',
              }}
            >
              {state.micEnabled ? <Mic /> : <MicOff />}
            </IconButton>
          </Tooltip>

          {/* 3Då¤´åƒåˆ‡æ¢ */}
          <Tooltip title={state.show3DAvatar ? 'åˆ‡æ¢åˆ°2Dæ¨¡å¼' : 'åˆ‡æ¢åˆ°3Då¤´åƒ'}>
            <IconButton
              onClick={toggle3DAvatar}
              color={state.show3DAvatar ? 'primary' : 'default'}
              sx={{
                bgcolor: state.show3DAvatar ? 'primary.dark' : 'action.hover',
              }}
            >
              {state.show3DAvatar ? <ThreeDRotation /> : <Face />}
            </IconButton>
          </Tooltip>

          {/* æ€è€ƒæµ‹è¯•æŒ‰é’® */}
          <Tooltip title="è§¦å‘æ·±åº¦æ€è€ƒ">
            <IconButton
              onClick={simulateThinking}
              disabled={state.isThinking}
              sx={{ gridColumn: 'span 3' }}
            >
              <Psychology />
            </IconButton>
          </Tooltip>
        </Box>

        {/* çŠ¶æ€ä¿¡æ¯ */}
        <Box sx={{ mt: 1 }}>
          <Typography variant="caption" color="text.secondary" display="block">
            çŠ¶æ€: {isConnected ? 'åœ¨çº¿' : 'ç¦»çº¿'} | 
            æ¨¡å¼: {state.show3DAvatar ? '3D' : '2D'} | 
            æ‘„åƒå¤´: {state.cameraEnabled ? 'å¼€' : 'å…³'} | 
            éº¦å…‹é£: {state.micEnabled ? 'å¼€' : 'å…³'}
          </Typography>
          
          <Typography variant="caption" color="text.secondary" display="block">
            è¯­éŸ³: {state.isListening ? 'ç›‘å¬ä¸­' : 'å¾…æœº'} | 
            åˆæˆ: {state.isSpeaking ? 'æ’­æ”¾ä¸­' : 'ç©ºé—²'} | 
            æƒ…æ„Ÿ: {state.currentEmotion}
          </Typography>
          
          {state.recognizedText && (
            <Typography variant="caption" color="primary" display="block" sx={{ mt: 0.5 }}>
              è¯†åˆ«: {state.recognizedText}
            </Typography>
          )}
          
          {jarvisStatus && (
            <Typography variant="caption" color="text.secondary" display="block">
              å¯¹è¯è½®æ¬¡: {jarvisStatus.conversation_turns || 0} | 
              æ´»è·ƒä»»åŠ¡: {jarvisStatus.active_tasks || 0}
            </Typography>
          )}
        </Box>
      </Paper>
    </Box>
  );
};

export default AvatarPanel;