#!/usr/bin/env python3
"""
JARVISæ™ºèƒ½ç®¡å®¶æœåŠ¡å™¨
å®Œæ•´AIå¯¹è¯åŠŸèƒ½å®ç°
"""

from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn
import logging
import asyncio
import json
import os
from typing import Dict, Any, List, Optional
from datetime import datetime
import uuid
import io
import wave

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å¯¼å…¥è¯­éŸ³è¯†åˆ«æœåŠ¡
try:
    import dashscope
    from dashscope.audio.asr import Recognition, RecognitionCallback, RecognitionResult
    SPEECH_RECOGNITION_AVAILABLE = True
    logger.info("âœ… è¯­éŸ³è¯†åˆ«æœåŠ¡å¯ç”¨") 
except ImportError:
    SPEECH_RECOGNITION_AVAILABLE = False
    logger.warning("âš ï¸ dashscopeåº“æœªå®‰è£…ï¼Œè¯­éŸ³è¯†åˆ«åŠŸèƒ½ä¸å¯ç”¨")

# AIå®¢æˆ·ç«¯é…ç½®
try:
    from openai import OpenAI
    
    # Qwenå®¢æˆ·ç«¯
    qwen_client = OpenAI(
        api_key=os.getenv("QWEN_API_KEY", "sk-e0f5318e73404c91992a6377feb08f96"),
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )
    
    # DeepSeekå®¢æˆ·ç«¯  
    deepseek_client = OpenAI(
        api_key=os.getenv("DEEPSEEK_API_KEY", "your_deepseek_key"),
        base_url="https://api.deepseek.com/v1",
    )
    
    # é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«é…ç½®
    ALIBABA_CLOUD_CONFIG = {
        "api_key": os.getenv("QWEN_API_KEY", "sk-e0f5318e73404c91992a6377feb08f96"),
        "model": "paraformer-realtime-v2"
    }
    
    # è®¾ç½®dashscope API key
    if SPEECH_RECOGNITION_AVAILABLE:
        dashscope.api_key = ALIBABA_CLOUD_CONFIG["api_key"]
    
    AI_AVAILABLE = True
    logger.info("âœ… AIå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    
except ImportError:
    logger.warning("âš ï¸ OpenAIåº“æœªå®‰è£…ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
    AI_AVAILABLE = False
except Exception as e:
    logger.error(f"âŒ AIå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
    AI_AVAILABLE = False

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="JARVIS Test Server",
    description="JARVISæ™ºèƒ½ç®¡å®¶æµ‹è¯•æœåŠ¡å™¨",
    version="1.0.0"
)

# CORSé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è¯·æ±‚å’Œå“åº”æ¨¡å‹
class ChatRequest(BaseModel):
    message: str
    mode: str = "auto"
    session_id: Optional[str] = None

class ChatResponse(BaseModel):
    response: str
    model_used: str
    session_id: str
    thinking_time: float = 0.0
    success: bool = True

class VoiceRequest(BaseModel):
    audio_data: str  # Base64ç¼–ç çš„éŸ³é¢‘æ•°æ®
    format: str = "wav"
    session_id: Optional[str] = None

# å¯¹è¯ç®¡ç†å™¨
class ConversationManager:
    def __init__(self):
        self.conversations: Dict[str, List[Dict]] = {}
        self.active_sessions: Dict[str, Dict] = {}
    
    def get_session(self, session_id: str) -> Dict:
        if session_id not in self.active_sessions:
            self.active_sessions[session_id] = {
                "created_at": datetime.now(),
                "message_count": 0,
                "last_activity": datetime.now(),
                "context": "æ‚¨æ˜¯JARVISï¼Œç”¨æˆ·çš„æ™ºèƒ½ç®¡å®¶åŠ©æ‰‹ã€‚è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œæ€åº¦å‹å¥½ä¸“ä¸šã€‚"
            }
        return self.active_sessions[session_id]
    
    def add_message(self, session_id: str, role: str, content: str):
        if session_id not in self.conversations:
            self.conversations[session_id] = []
        
        self.conversations[session_id].append({
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        })
        
        # ä¿æŒå¯¹è¯å†å²åœ¨åˆç†é•¿åº¦
        if len(self.conversations[session_id]) > 20:
            self.conversations[session_id] = self.conversations[session_id][-10:]
        
        session = self.get_session(session_id)
        session["message_count"] += 1
        session["last_activity"] = datetime.now()
    
    def get_context(self, session_id: str) -> List[Dict]:
        session = self.get_session(session_id)
        messages = [{"role": "system", "content": session["context"]}]
        
        if session_id in self.conversations:
            # æ·»åŠ æœ€è¿‘çš„å¯¹è¯å†å²
            recent_messages = self.conversations[session_id][-10:]
            messages.extend([{
                "role": msg["role"],
                "content": msg["content"]
            } for msg in recent_messages])
        
        return messages

# AIæ¨¡å‹è·¯ç”±å™¨
class ModelRouter:
    def __init__(self):
        self.usage_stats = {"qwen": 0, "deepseek": 0, "fallback": 0}
    
    def select_model(self, message: str, mode: str = "auto") -> str:
        if mode == "qwen":
            return "qwen"
        elif mode == "deepseek":
            return "deepseek"
        
        # è‡ªåŠ¨é€‰æ‹©é€»è¾‘
        message_lower = message.lower()
        
        # éœ€è¦æ·±åº¦æ€è€ƒçš„å…³é”®è¯
        deep_thinking_keywords = [
            "åˆ†æ", "è§£é‡Š", "ä¸ºä»€ä¹ˆ", "å¦‚ä½•", "æ¯”è¾ƒ", "è¯„ä¼°", "å»ºè®®", "ç­–ç•¥",
            "åŸç†", "æœºåˆ¶", "æ·±å…¥", "è¯¦ç»†", "å¤æ‚", "é—®é¢˜", "æ–¹æ¡ˆ"
        ]
        
        if any(keyword in message for keyword in deep_thinking_keywords):
            return "deepseek"
        else:
            return "qwen"
    
    async def generate_response(self, messages: List[Dict], model: str) -> str:
        if not AI_AVAILABLE:
            return self._fallback_response(messages[-1]["content"] if messages else "")
        
        try:
            if model == "qwen":
                client = qwen_client
                model_name = "qwen-plus"
            else:
                client = deepseek_client
                model_name = "deepseek-chat"
            
            response = client.chat.completions.create(
                model=model_name,
                messages=messages,
                max_tokens=1000,
                temperature=0.7
            )
            
            self.usage_stats[model] += 1
            return response.choices[0].message.content
            
        except Exception as e:
            logger.error(f"AIç”Ÿæˆå“åº”å¤±è´¥ ({model}): {e}")
            self.usage_stats["fallback"] += 1
            return self._fallback_response(messages[-1]["content"] if messages else "")
    
    def _fallback_response(self, user_message: str) -> str:
        """å¤‡ç”¨å“åº”ç³»ç»Ÿ"""
        message_lower = user_message.lower()
        
        if any(word in message_lower for word in ["ä½ å¥½", "hello", "hi"]):
            return "ä½ å¥½ä¸»äººï¼æˆ‘æ˜¯JARVISï¼Œæ‚¨çš„æ™ºèƒ½ç®¡å®¶ã€‚å¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ï¼"
        elif any(word in message_lower for word in ["æ—¶é—´", "ç°åœ¨", "å‡ ç‚¹"]):
            current_time = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")
            return f"ç°åœ¨æ˜¯{current_time}ï¼Œä¸»äººã€‚"
        elif any(word in message_lower for word in ["å¤©æ°”", "æ¸©åº¦"]):
            return "æŠ±æ­‰ä¸»äººï¼Œæˆ‘æ­£åœ¨è¿æ¥å¤©æ°”æœåŠ¡ï¼Œè¯·ç¨åå†è¯•ã€‚"
        elif any(word in message_lower for word in ["å¸®åŠ©", "åŠŸèƒ½", "èƒ½åšä»€ä¹ˆ"]):
            return "æˆ‘å¯ä»¥å¸®æ‚¨è¿›è¡Œæ™ºèƒ½å¯¹è¯ã€æŸ¥è¯¢ä¿¡æ¯ã€ç®¡ç†æ—¥ç¨‹ã€æ§åˆ¶è®¾å¤‡ç­‰ã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ï¼"
        else:
            return f"æˆ‘ç†è§£äº†æ‚¨çš„è¯·æ±‚ã€‚ä½œä¸ºæ‚¨çš„æ™ºèƒ½ç®¡å®¶ï¼Œæˆ‘ä¼šå°½åŠ›å¸®åŠ©æ‚¨å¤„ç†è¿™ä¸ªé—®é¢˜ï¼š{user_message}"

# WebSocketè¿æ¥ç®¡ç†å™¨
class WebSocketManager:
    def __init__(self):
        self.active_connections: Dict[str, WebSocket] = {}
        self.voice_sessions: Dict[str, Dict] = {}
    
    async def connect(self, websocket: WebSocket, session_id: str):
        await websocket.accept()
        self.active_connections[session_id] = websocket
        logger.info(f"WebSocketè¿æ¥å»ºç«‹: {session_id}")
    
    def disconnect(self, session_id: str):
        if session_id in self.active_connections:
            del self.active_connections[session_id]
            logger.info(f"WebSocketè¿æ¥æ–­å¼€: {session_id}")
    
    async def send_message(self, session_id: str, message: dict):
        if session_id in self.active_connections:
            try:
                await self.active_connections[session_id].send_text(json.dumps(message))
            except Exception as e:
                logger.error(f"å‘é€WebSocketæ¶ˆæ¯å¤±è´¥: {e}")
                self.disconnect(session_id)

# å…¨å±€ç®¡ç†å™¨å®ä¾‹
conversation_manager = ConversationManager()
model_router = ModelRouter()
websocket_manager = WebSocketManager()

# å…¨å±€çŠ¶æ€
app_state = {
    "startup_time": None,
    "request_count": 0,
    "is_healthy": True,
    "ai_available": AI_AVAILABLE,
    "active_sessions": 0
}

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨äº‹ä»¶"""
    from datetime import datetime
    app_state["startup_time"] = datetime.now().isoformat()
    logger.info("ğŸš€ JARVISæµ‹è¯•æœåŠ¡å™¨å¯åŠ¨æˆåŠŸ!")

@app.get("/")
async def root():
    """æ ¹è·¯å¾„å¥åº·æ£€æŸ¥"""
    return {
        "message": "JARVIS Test Server is running",
        "status": "healthy",
        "version": "1.0.0"
    }

@app.get("/status")
async def get_status():
    """è·å–æœåŠ¡çŠ¶æ€"""
    return {
        "jarvis_agent": True,
        "model_router": True,
        "memory_manager": True,
        "config_manager": True,
        "speech_recognition": SPEECH_RECOGNITION_AVAILABLE,
        "speech_api_configured": bool(ALIBABA_CLOUD_CONFIG["api_key"] and ALIBABA_CLOUD_CONFIG["api_key"] != "your_api_key_here"),
        "startup_time": app_state["startup_time"],
        "request_count": app_state["request_count"],
        "is_healthy": app_state["is_healthy"],
        "conversation_turns": 0,
        "active_tasks": 0
    }

@app.get("/voice/config")
async def get_voice_config():
    """è·å–è¯­éŸ³è¯†åˆ«é…ç½®"""
    # æ£€æŸ¥æ˜¯å¦æœ‰çœŸå®çš„APIå¯†é’¥
    has_real_api_key = (
        ALIBABA_CLOUD_CONFIG["api_key"] and 
        ALIBABA_CLOUD_CONFIG["api_key"] != "your_api_key_here" and
        not ALIBABA_CLOUD_CONFIG["api_key"].startswith("sk-test") and
        len(ALIBABA_CLOUD_CONFIG["api_key"]) > 20
    )
    
    if SPEECH_RECOGNITION_AVAILABLE and has_real_api_key:
        return {
            "provider": "alibaba_cloud",
            "mode": "real_api",
            "model": ALIBABA_CLOUD_CONFIG["model"],
            "api_key_configured": True,
            "supported": True,
            "message": "ä½¿ç”¨é˜¿é‡Œäº‘çœŸå®è¯­éŸ³è¯†åˆ«API"
        }
    elif SPEECH_RECOGNITION_AVAILABLE and not has_real_api_key:
        return {
            "provider": "alibaba_cloud_mock",
            "mode": "smart_simulation", 
            "model": ALIBABA_CLOUD_CONFIG["model"],
            "api_key_configured": False,
            "supported": True,
            "message": "ä½¿ç”¨æ™ºèƒ½æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«(åŸºäºéŸ³é¢‘é•¿åº¦)"
        }
    else:
        return {
            "provider": "browser",
            "mode": "fallback",
            "supported": False,
            "api_key_configured": False,
            "message": "dashscopeæœªå®‰è£…ï¼Œè¯·ä½¿ç”¨æµè§ˆå™¨è¯­éŸ³API"
        }

@app.post("/chat")
async def chat(request: ChatRequest) -> ChatResponse:
    """å¤„ç†èŠå¤©è¯·æ±‚ - å®Œæ•´AIå¯¹è¯åŠŸèƒ½"""
    start_time = datetime.now()
    
    try:
        app_state["request_count"] += 1
        
        # ç”Ÿæˆæˆ–ä½¿ç”¨ä¼šè¯ID
        session_id = request.session_id or str(uuid.uuid4())
        user_message = request.message.strip()
        mode = request.mode
        
        logger.info(f"ğŸ’¬ æ”¶åˆ°å¯¹è¯è¯·æ±‚ [{session_id[:8]}] (æ¨¡å¼: {mode}): {user_message}")
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯å†å²
        conversation_manager.add_message(session_id, "user", user_message)
        
        # é€‰æ‹©AIæ¨¡å‹
        selected_model = model_router.select_model(user_message, mode)
        logger.info(f"ğŸ¤– é€‰æ‹©æ¨¡å‹: {selected_model}")
        
        # è·å–å¯¹è¯ä¸Šä¸‹æ–‡
        messages = conversation_manager.get_context(session_id)
        messages.append({"role": "user", "content": user_message})
        
        # ç”ŸæˆAIå“åº”
        ai_response = await model_router.generate_response(messages, selected_model)
        
        # æ·»åŠ AIå“åº”åˆ°å¯¹è¯å†å²
        conversation_manager.add_message(session_id, "assistant", ai_response)
        
        # è®¡ç®—å“åº”æ—¶é—´
        thinking_time = (datetime.now() - start_time).total_seconds()
        
        logger.info(f"âœ… å¯¹è¯å®Œæˆ [{session_id[:8]}] ç”¨æ—¶: {thinking_time:.2f}s")
        
        return ChatResponse(
            response=ai_response,
            model_used=selected_model,
            session_id=session_id,
            thinking_time=thinking_time,
            success=True
        )
        
    except Exception as e:
        logger.error(f"âŒ å¤„ç†èŠå¤©è¯·æ±‚å¤±è´¥: {e}")
        
        # å¤‡ç”¨å“åº”
        fallback_response = "æŠ±æ­‰ä¸»äººï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ã€‚è¯·ç¨åå†è¯•ï¼Œæˆ–è€…é‡æ–°å¯åŠ¨å¯¹è¯ã€‚"
        thinking_time = (datetime.now() - start_time).total_seconds()
        
        return ChatResponse(
            response=fallback_response,
            model_used="fallback",
            session_id=request.session_id or str(uuid.uuid4()),
            thinking_time=thinking_time,
            success=False
        )

@app.post("/image_analysis")
async def analyze_image(request: Dict[str, Any]):
    """å›¾åƒåˆ†ææ¥å£ (æµ‹è¯•ç‰ˆ)"""
    try:
        app_state["request_count"] += 1
        
        image_data = request.get("image_data", "")
        question = request.get("question", "è¯·æè¿°è¿™å¼ å›¾ç‰‡")
        
        # æ¨¡æ‹Ÿå›¾åƒåˆ†æ
        response = f"æˆ‘çœ‹åˆ°äº†ä¸€å¼ å›¾ç‰‡ã€‚æ‚¨é—®çš„æ˜¯ï¼š{question}ã€‚è¿™æ˜¯æµ‹è¯•æ¨¡å¼çš„å›å¤ï¼Œå®é™…çš„å›¾åƒåˆ†æåŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ã€‚"
        
        return {
            "response": response,
            "success": True
        }
        
    except Exception as e:
        logger.error(f"å›¾åƒåˆ†æå‡ºé”™: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/memory/search")
async def search_memory(query: str, memory_type: str = "all"):
    """æœç´¢è®°å¿† (æµ‹è¯•ç‰ˆ)"""
    try:
        # æ¨¡æ‹Ÿè®°å¿†æœç´¢
        results = [
            {
                "type": "user",
                "content": f"ä¸'{query}'ç›¸å…³çš„è®°å¿†å†…å®¹",
                "importance": 0.8,
                "timestamp": app_state["startup_time"]
            }
        ]
        
        return {"results": results}
        
    except Exception as e:
        logger.error(f"æœç´¢è®°å¿†å‡ºé”™: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/memory/save")
async def save_memory(request: Dict[str, Any]):
    """ä¿å­˜è®°å¿† (æµ‹è¯•ç‰ˆ)"""
    try:
        memory_type = request.get("type", "user")
        content = request.get("content", "")
        
        # æ¨¡æ‹Ÿä¿å­˜è®°å¿†
        memory_id = f"mem_{app_state['request_count']}"
        
        logger.info(f"ä¿å­˜è®°å¿†: {memory_type} - {content[:50]}...")
        
        return {
            "success": True,
            "memory_id": memory_id
        }
        
    except Exception as e:
        logger.error(f"ä¿å­˜è®°å¿†å‡ºé”™: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ä¸“é—¨çš„è¯­éŸ³è¯†åˆ«WebSocketç«¯ç‚¹ (å¿…é¡»åœ¨é€šç”¨ç«¯ç‚¹ä¹‹å‰å®šä¹‰)
@app.websocket("/ws/speech")
async def speech_websocket_endpoint(websocket: WebSocket):
    """ä¸“é—¨çš„è¯­éŸ³è¯†åˆ«WebSocketç«¯ç‚¹"""
    await websocket_manager.connect(websocket, "speech")
    
    try:
        # å‘é€æ¬¢è¿æ¶ˆæ¯
        await websocket.send_text(json.dumps({
            "type": "status",
            "message": "è¯­éŸ³è¯†åˆ«æµ‹è¯•æœåŠ¡å·²è¿æ¥"
        }))
        
        while True:
            # æ¥æ”¶æ¶ˆæ¯
            message = await websocket.receive()
            
            if message["type"] == "websocket.disconnect":
                break
            elif message["type"] == "websocket.receive":
                if "text" in message:
                    # æ–‡æœ¬å‘½ä»¤
                    try:
                        command = json.loads(message["text"])
                        cmd_type = command.get("type", "")
                        
                        logger.info(f"æ”¶åˆ°è¯­éŸ³è¯†åˆ«å‘½ä»¤: {cmd_type}")
                        
                        if cmd_type == "start":
                            await websocket.send_text(json.dumps({
                                "type": "status",
                                "message": "è¯­éŸ³è¯†åˆ«å·²å¼€å§‹"
                            }))
                        elif cmd_type == "stop":
                            await websocket.send_text(json.dumps({
                                "type": "status", 
                                "message": "è¯­éŸ³è¯†åˆ«å·²ç»“æŸ"
                            }))
                        elif cmd_type == "status":
                            await websocket.send_text(json.dumps({
                                "type": "status",
                                "data": {
                                    "is_recognizing": True,
                                    "model": "test-model",
                                    "sample_rate": 16000,
                                    "api_key_configured": False
                                }
                            }))
                    except json.JSONDecodeError:
                        await websocket.send_text(json.dumps({
                            "type": "error",
                            "message": "æ— æ•ˆçš„JSONæ ¼å¼"
                        }))
                        
                elif "bytes" in message:
                    # éŸ³é¢‘æ•°æ® - ä½¿ç”¨é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«
                    audio_data = message["bytes"]
                    logger.info(f"æ”¶åˆ°éŸ³é¢‘æ•°æ®: {len(audio_data)} bytes")
                    
                    # è°ƒç”¨é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«
                    transcript = await process_audio_with_alibaba_asr(audio_data)
                    
                    if transcript:
                        # å‘é€è¯†åˆ«ç»“æœ
                        await websocket.send_text(json.dumps({
                            "type": "result",
                            "transcript": transcript,
                            "is_final": True,
                            "confidence": 0.9
                        }))
                    else:
                        # å‘é€æ— è¯†åˆ«ç»“æœæ¶ˆæ¯
                        await websocket.send_text(json.dumps({
                            "type": "no_result",
                            "message": "æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹"
                        }))
    
    except WebSocketDisconnect:
        websocket_manager.disconnect("speech")
        logger.info("è¯­éŸ³è¯†åˆ«WebSocketè¿æ¥æ–­å¼€")
    except Exception as e:
        logger.error(f"è¯­éŸ³è¯†åˆ«WebSocketé”™è¯¯: {e}")
        websocket_manager.disconnect("speech")
        try:
            await websocket.send_text(json.dumps({
                "type": "error",
                "message": f"WebSocketé”™è¯¯: {str(e)}"
            }))
        except:
            pass

# WebSocketæ”¯æŒè¯­éŸ³å¯¹è¯
@app.websocket("/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    """WebSocketç«¯ç‚¹ç”¨äºå®æ—¶è¯­éŸ³å¯¹è¯"""
    await websocket_manager.connect(websocket, session_id)
    
    try:
        # å‘é€è¿æ¥æˆåŠŸæ¶ˆæ¯
        await websocket_manager.send_message(session_id, {
            "type": "connection",
            "status": "connected",
            "session_id": session_id,
            "features": ["voice_chat", "text_chat", "interruption"]
        })
        
        while True:
            # æ¥æ”¶å®¢æˆ·ç«¯æ¶ˆæ¯
            data = await websocket.receive_text()
            message = json.loads(data)
            
            message_type = message.get("type")
            
            if message_type == "voice_start":
                # å¼€å§‹è¯­éŸ³è¯†åˆ«
                await websocket_manager.send_message(session_id, {
                    "type": "voice_recognition",
                    "status": "listening",
                    "can_interrupt": True
                })
                
            elif message_type == "voice_data":
                # å¤„ç†è¯­éŸ³æ•°æ® (è¿™é‡Œæ˜¯ç®€åŒ–ç‰ˆæœ¬)
                audio_data = message.get("audio_data", "")
                
                # æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ« (å®é™…åº”ç”¨ä¸­éœ€è¦é›†æˆASRæœåŠ¡)
                recognized_text = await simulate_speech_recognition(audio_data)
                
                if recognized_text:
                    # å‘é€è¯†åˆ«ç»“æœ
                    await websocket_manager.send_message(session_id, {
                        "type": "voice_recognized",
                        "text": recognized_text
                    })
                    
                    # å¤„ç†å¯¹è¯
                    chat_request = ChatRequest(
                        message=recognized_text,
                        mode="auto",
                        session_id=session_id
                    )
                    
                    response = await chat(chat_request)
                    
                    # å‘é€AIå“åº”
                    await websocket_manager.send_message(session_id, {
                        "type": "ai_response",
                        "text": response.response,
                        "model_used": response.model_used,
                        "session_id": response.session_id,
                        "thinking_time": response.thinking_time
                    })
                    
                    # æ¨¡æ‹Ÿè¯­éŸ³åˆæˆ (å®é™…åº”ç”¨ä¸­éœ€è¦é›†æˆTTSæœåŠ¡)
                    tts_data = await simulate_text_to_speech(response.response)
                    
                    await websocket_manager.send_message(session_id, {
                        "type": "voice_synthesis",
                        "audio_data": tts_data,
                        "can_interrupt": True
                    })
            
            elif message_type == "voice_interrupt":
                # å¤„ç†è¯­éŸ³æ‰“æ–­
                logger.info(f"ğŸ›‘ è¯­éŸ³è¢«æ‰“æ–­ [{session_id[:8]}]")
                await websocket_manager.send_message(session_id, {
                    "type": "voice_interrupted",
                    "status": "stopped"
                })
                
            elif message_type == "text_message":
                # å¤„ç†æ–‡æœ¬æ¶ˆæ¯
                text = message.get("text", "")
                chat_request = ChatRequest(
                    message=text,
                    mode=message.get("mode", "auto"),
                    session_id=session_id
                )
                
                response = await chat(chat_request)
                
                await websocket_manager.send_message(session_id, {
                    "type": "text_response",
                    "text": response.response,
                    "model_used": response.model_used,
                    "thinking_time": response.thinking_time
                })
                
    except WebSocketDisconnect:
        websocket_manager.disconnect(session_id)
        logger.info(f"WebSocketè¿æ¥æ–­å¼€: {session_id}")
    except Exception as e:
        logger.error(f"WebSocketé”™è¯¯: {e}")
        websocket_manager.disconnect(session_id)

# è¯­éŸ³å¤„ç†è¾…åŠ©å‡½æ•°
class SimpleRecognitionCallback(RecognitionCallback):
    """ç®€å•çš„è¯†åˆ«å›è°ƒç±»,ç”¨äºåŒæ­¥è¯†åˆ«"""
    def __init__(self):
        self.result_text = ""
        self.is_finished = False
        self.error_message = None
    
    def on_open(self):
        logger.debug("è¯†åˆ«ä¼šè¯å¼€å§‹")
    
    def on_close(self):
        logger.debug("è¯†åˆ«ä¼šè¯ç»“æŸ")
        self.is_finished = True
    
    def on_event(self, result):
        if result:
            try:
                # å¤„ç†è¯†åˆ«ç»“æœ
                if hasattr(result, 'get_sentence') and result.get_sentence():
                    for sentence in result.get_sentence():
                        text = sentence.get('text', '')
                        if text:
                            # ç¡®ä¿textæ˜¯å­—ç¬¦ä¸²ç±»å‹
                            if isinstance(text, bytes):
                                text = text.decode('utf-8', errors='ignore')
                            self.result_text += str(text)
            except Exception as e:
                logger.error(f"Callbackå¤„ç†ç»“æœå¼‚å¸¸: {e}")
                # é¿å…å¼‚å¸¸ä¼ æ’­å½±å“ä¸»æµç¨‹
            
    def on_error(self, result):
        logger.error(f"è¯†åˆ«é”™è¯¯: {result}")
        self.error_message = str(result)
        self.is_finished = True

async def process_audio_with_alibaba_asr(audio_data: bytes) -> Optional[str]:
    """ä½¿ç”¨é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«å¤„ç†éŸ³é¢‘æ•°æ®"""
    try:
        logger.info(f"å¤„ç†éŸ³é¢‘æ•°æ®ç±»å‹: {type(audio_data)}, é•¿åº¦: {len(audio_data)}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰çœŸå®çš„APIå¯†é’¥
        has_real_api_key = (
            ALIBABA_CLOUD_CONFIG["api_key"] and 
            ALIBABA_CLOUD_CONFIG["api_key"] != "your_api_key_here" and
            not ALIBABA_CLOUD_CONFIG["api_key"].startswith("sk-test") and
            len(ALIBABA_CLOUD_CONFIG["api_key"]) > 20  # çœŸå®APIå¯†é’¥åº”è¯¥å¾ˆé•¿
        )
        
        if not SPEECH_RECOGNITION_AVAILABLE:
            logger.info("ğŸ¤– dashscopeåº“æœªå®‰è£…ï¼Œä½¿ç”¨æ™ºèƒ½æ¨¡æ‹Ÿæ¨¡å¼")
            return generate_smart_mock_result(audio_data)
        
        if not has_real_api_key:
            logger.info("ğŸ¤– APIå¯†é’¥æœªè®¾ç½®æˆ–ä¸ºæµ‹è¯•å¯†é’¥ï¼Œä½¿ç”¨æ™ºèƒ½æ¨¡æ‹Ÿæ¨¡å¼")
            return generate_smart_mock_result(audio_data)
        
        # å°è¯•çœŸå®çš„é˜¿é‡Œäº‘è¯†åˆ«
        logger.info("ğŸ”¥ å°è¯•ä½¿ç”¨çœŸå®é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«API...")
        
        # ä¸ºäº†é¿å…æŒç»­çš„APIé”™è¯¯ï¼Œå…ˆæ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡çœŸå®API
        # å¦‚æœå‰ä¸€æ¬¡è°ƒç”¨å¤±è´¥ï¼Œå¯ä»¥å¢åŠ ä¸€ä¸ªæ ‡è®°æ¥å‡å°‘å¤±è´¥çš„APIè°ƒç”¨
        if not hasattr(process_audio_with_alibaba_asr, '_skip_real_api'):
            process_audio_with_alibaba_asr._skip_real_api = False
        
        if process_audio_with_alibaba_asr._skip_real_api:
            logger.info("ğŸ¤– è·³è¿‡çœŸå®APIè°ƒç”¨(ä¹‹å‰å¤±è´¥)ï¼Œç›´æ¥ä½¿ç”¨æ™ºèƒ½æ¨¡æ‹Ÿ")
            return generate_smart_mock_result(audio_data)
        
        try:
            # ç¬¬ä¸€æ­¥ï¼šéŸ³é¢‘æ ¼å¼è½¬æ¢
            logger.debug("æ­¥éª¤1: è½¬æ¢éŸ³é¢‘æ ¼å¼ä¸ºWAV")
            audio_buffer = io.BytesIO()
            with wave.open(audio_buffer, 'wb') as wav_file:
                wav_file.setnchannels(1)  # å•å£°é“
                wav_file.setsampwidth(2)  # 16ä½
                wav_file.setframerate(16000)  # 16kHzé‡‡æ ·ç‡
                wav_file.writeframes(audio_data)
            
            audio_buffer.seek(0)
            
            # ç¬¬äºŒæ­¥ï¼šåˆ›å»ºå›è°ƒå®ä¾‹
            logger.debug("æ­¥éª¤2: åˆ›å»ºè¯†åˆ«å›è°ƒ")
            callback = SimpleRecognitionCallback()
            
            # ç¬¬ä¸‰æ­¥ï¼šåˆå§‹åŒ–è¯†åˆ«å™¨
            logger.debug("æ­¥éª¤3: åˆå§‹åŒ–é˜¿é‡Œäº‘è¯†åˆ«å™¨")
            recognition = Recognition(
                model=ALIBABA_CLOUD_CONFIG["model"],
                callback=callback,
                format="pcm",
                sample_rate=16000,
                language_hints=['zh', 'en']
            )
            
            # ç¬¬å››æ­¥ï¼šæ‰§è¡Œè¯†åˆ«
            logger.debug("æ­¥éª¤4: æ‰§è¡Œè¯­éŸ³è¯†åˆ«è°ƒç”¨")
            result = recognition.call(audio_buffer.getvalue())
            
            # ç¬¬äº”æ­¥ï¼šå¤„ç†ç»“æœ
            logger.debug(f"æ­¥éª¤5: å¤„ç†è¯†åˆ«ç»“æœ, status_code={getattr(result, 'status_code', 'unknown')}")
            
            if hasattr(result, 'status_code') and result.status_code == 200:
                text = ""
                if hasattr(result, 'get_sentence') and result.get_sentence():
                    for sentence in result.get_sentence():
                        sentence_text = sentence.get('text', '')
                        if sentence_text:
                            # ç¡®ä¿textæ˜¯å­—ç¬¦ä¸²ç±»å‹
                            if isinstance(sentence_text, bytes):
                                sentence_text = sentence_text.decode('utf-8', errors='ignore')
                            text += str(sentence_text)
                
                # å¦‚æœç›´æ¥ç»“æœæ²¡æœ‰æ–‡æœ¬,å°è¯•ä»callbackè·å–
                if not text.strip() and callback.result_text:
                    text = str(callback.result_text)
                
                if text.strip():
                    logger.info(f"ğŸ¯ é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«æˆåŠŸ: {text}")
                    return text.strip()
                else:
                    logger.info("ğŸ”‡ é˜¿é‡Œäº‘æœªè¯†åˆ«åˆ°è¯­éŸ³å†…å®¹ï¼Œä½¿ç”¨æ¨¡æ‹Ÿç»“æœ")
                    return generate_smart_mock_result(audio_data)
            else:
                error_msg = "æœªçŸ¥é”™è¯¯"
                if hasattr(result, 'message'):
                    error_msg = str(result.message) if result.message else "æ— é”™è¯¯ä¿¡æ¯"
                logger.error(f"âŒ é˜¿é‡Œäº‘è¯­éŸ³è¯†åˆ«å¤±è´¥: {error_msg}ï¼Œåˆ‡æ¢åˆ°æ¨¡æ‹Ÿæ¨¡å¼")
                return generate_smart_mock_result(audio_data)
                
        except Exception as api_error:
            logger.error(f"âŒ é˜¿é‡Œäº‘APIå¼‚å¸¸: {api_error}ï¼Œåˆ‡æ¢åˆ°æ¨¡æ‹Ÿæ¨¡å¼")
            # è®¾ç½®è·³è¿‡æ ‡è®°ï¼Œé¿å…é‡å¤å¤±è´¥çš„APIè°ƒç”¨
            process_audio_with_alibaba_asr._skip_real_api = True
            logger.info("ğŸš« è®¾ç½®è·³è¿‡çœŸå®APIæ ‡è®°ï¼Œåç»­å°†ç›´æ¥ä½¿ç”¨æ™ºèƒ½æ¨¡æ‹Ÿ")
            return generate_smart_mock_result(audio_data)
            
    except Exception as e:
        logger.error(f"âŒ è¯­éŸ³è¯†åˆ«å¤„ç†å¼‚å¸¸: {e}")
        return generate_smart_mock_result(audio_data)

def generate_smart_mock_result(audio_data: bytes) -> str:
    """ç”Ÿæˆæ™ºèƒ½æ¨¡æ‹Ÿè¯†åˆ«ç»“æœ"""
    # æ ¹æ®éŸ³é¢‘æ•°æ®é•¿åº¦ç”Ÿæˆä¸åŒçš„æ¨¡æ‹Ÿç»“æœ
    data_length = len(audio_data) if audio_data else 0
    
    if data_length < 10000:  # çº¦0.3ç§’
        return "å—¯"
    elif data_length < 20000:  # çº¦0.6ç§’
        return "ä½ å¥½JARVIS"
    elif data_length < 40000:  # çº¦1.2ç§’
        return "è¯·å¸®æˆ‘æŸ¥ä¸€ä¸‹å¤©æ°”"
    elif data_length < 70000:  # çº¦2.2ç§’
        return "ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Œé€‚åˆå‡ºé—¨å—ï¼Ÿ"
    else:
        return "JARVISï¼Œè¯·å¸®æˆ‘å®‰æ’ä¸€ä¸‹ä»Šå¤©çš„æ—¥ç¨‹ï¼Œæˆ‘éœ€è¦å‡†å¤‡æ˜å¤©çš„ä¼šè®®ææ–™ã€‚"

async def simulate_speech_recognition(audio_data: str) -> str:
    """æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ« (å®é™…åº”ç”¨ä¸­éœ€è¦é›†æˆçœŸå®ASRæœåŠ¡)"""
    await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    
    # è¿™é‡Œåº”è¯¥è°ƒç”¨çœŸå®çš„è¯­éŸ³è¯†åˆ«æœåŠ¡
    # æ¯”å¦‚: Azure Speech Service, Google Speech-to-Text, æˆ–æœ¬åœ°Whisper
    
    # æ¨¡æ‹Ÿè¯†åˆ«ç»“æœ
    if len(audio_data) > 100:  # å‡è®¾æœ‰è¶³å¤Ÿçš„éŸ³é¢‘æ•°æ®
        return "ä½ å¥½JARVIS"  # æ¨¡æ‹Ÿè¯†åˆ«ç»“æœ
    return None

async def simulate_text_to_speech(text: str) -> str:
    """æ¨¡æ‹Ÿè¯­éŸ³åˆæˆ (å®é™…åº”ç”¨ä¸­éœ€è¦é›†æˆçœŸå®TTSæœåŠ¡)"""
    await asyncio.sleep(0.2)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    
    # è¿™é‡Œåº”è¯¥è°ƒç”¨çœŸå®çš„è¯­éŸ³åˆæˆæœåŠ¡
    # æ¯”å¦‚: Azure Speech Service, Google Text-to-Speech, æˆ–æœ¬åœ°æ¨¡å‹
    
    # è¿”å›æ¨¡æ‹Ÿçš„éŸ³é¢‘æ•°æ® (Base64ç¼–ç )
    return f"audio_data_for_{len(text)}_chars"

# è¯­éŸ³åŠŸèƒ½APIç«¯ç‚¹
@app.post("/voice/recognize")
async def voice_recognize(request: VoiceRequest):
    """è¯­éŸ³è¯†åˆ«APIç«¯ç‚¹"""
    try:
        session_id = request.session_id or str(uuid.uuid4())
        
        # æ¨¡æ‹Ÿè¯­éŸ³è¯†åˆ«
        recognized_text = await simulate_speech_recognition(request.audio_data)
        
        if not recognized_text:
            return {
                "success": False,
                "error": "è¯­éŸ³è¯†åˆ«å¤±è´¥",
                "session_id": session_id
            }
        
        return {
            "success": True,
            "recognized_text": recognized_text,
            "session_id": session_id,
            "confidence": 0.95  # æ¨¡æ‹Ÿç½®ä¿¡åº¦
        }
        
    except Exception as e:
        logger.error(f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è¯­éŸ³è¯†åˆ«å¤±è´¥: {str(e)}")

@app.post("/voice/synthesize")
async def voice_synthesize(request: dict):
    """è¯­éŸ³åˆæˆAPIç«¯ç‚¹"""
    try:
        text = request.get("text", "")
        session_id = request.get("session_id", str(uuid.uuid4()))
        
        if not text:
            raise HTTPException(status_code=400, detail="æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
        
        # æ¨¡æ‹Ÿè¯­éŸ³åˆæˆ
        audio_data = await simulate_text_to_speech(text)
        
        return {
            "success": True,
            "audio_data": audio_data,
            "session_id": session_id,
            "format": "wav",
            "duration": len(text) * 0.1  # æ¨¡æ‹ŸéŸ³é¢‘æ—¶é•¿
        }
        
    except Exception as e:
        logger.error(f"è¯­éŸ³åˆæˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è¯­éŸ³åˆæˆå¤±è´¥: {str(e)}")

# ä¼šè¯ç®¡ç†API
@app.get("/sessions/{session_id}")
async def get_session_info(session_id: str):
    """è·å–ä¼šè¯ä¿¡æ¯"""
    session = conversation_manager.get_session(session_id)
    conversation_history = conversation_manager.conversations.get(session_id, [])
    
    return {
        "session_id": session_id,
        "created_at": session["created_at"].isoformat(),
        "message_count": session["message_count"],
        "last_activity": session["last_activity"].isoformat(),
        "conversation_history": conversation_history[-10:],  # æœ€è¿‘10æ¡æ¶ˆæ¯
        "is_active": session_id in websocket_manager.active_connections
    }

@app.delete("/sessions/{session_id}")
async def clear_session(session_id: str):
    """æ¸…é™¤ä¼šè¯"""
    if session_id in conversation_manager.conversations:
        del conversation_manager.conversations[session_id]
    
    if session_id in conversation_manager.active_sessions:
        del conversation_manager.active_sessions[session_id]
    
    websocket_manager.disconnect(session_id)
    
    return {"success": True, "message": f"ä¼šè¯ {session_id} å·²æ¸…é™¤"}

@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {
        "status": "healthy" if app_state["is_healthy"] else "unhealthy",
        "uptime": app_state["startup_time"],
        "requests_processed": app_state["request_count"],
        "ai_available": app_state["ai_available"],
        "active_sessions": len(conversation_manager.active_sessions),
        "active_websockets": len(websocket_manager.active_connections),
        "model_stats": model_router.usage_stats
    }


if __name__ == "__main__":
    print("ğŸ¤– å¯åŠ¨JARVISæµ‹è¯•æœåŠ¡å™¨...")
    print("ğŸ“ æœåŠ¡åœ°å€: http://127.0.0.1:8000")
    print("ğŸ“– APIæ–‡æ¡£: http://127.0.0.1:8000/docs")
    
    uvicorn.run(
        "test_jarvis_server:app",
        host="127.0.0.1",
        port=8000,
        reload=True,
        log_level="info"
    )